{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Magical Mexican Towns Training Corpus - Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import wasabi\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Users/roicort/GitHub/REST-MEX25/dataset/train.csv')\n",
    "\n",
    "df['Title'] = df['Title'].astype(str)\n",
    "df['Review'] = df['Review'].astype(str)\n",
    "df['Town'] = df['Town'].astype(str)\n",
    "df['Region'] = df['Region'].astype(str)\n",
    "df['Type'] = df['Type'].astype(str)\n",
    "df['Polarity'] = df['Polarity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the spanish model\n",
    "#!python -m spacy download es_dep_news_trf \n",
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Tokenize the text data\n",
    "\n",
    "def tokenize_text(text, nlp):\n",
    "    \"\"\"\n",
    "    Tokenize the input text, removing punctuation, stopwords, and converting to lowercase.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to tokenize.\n",
    "        nlp (spacy.Language): The spaCy language model.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of processed tokens.\n",
    "    \"\"\"\n",
    "    # Procesar el texto con el modelo de spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extraer tokens, eliminar puntuación, stopwords y convertir a minúsculas\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_stop]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208051/208051 [04:08<00:00, 837.46it/s]\n",
      "100%|██████████| 208051/208051 [14:14<00:00, 243.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Title data with progress bar\n",
    "df['Title_tokens'] = df['Title'].progress_apply(lambda x: tokenize_text(x, nlp))\n",
    "\n",
    "# Tokenize the Review data with progress bar\n",
    "df['Review_tokens'] = df['Review'].progress_apply(lambda x: tokenize_text(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (156038, 8)\n",
      "Validation shape: (31207, 8)\n",
      "Test shape: (20806, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.25, random_state=42)\n",
    "val, test = train_test_split(test, test_size=0.4, random_state=42)\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Validation shape: {val.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(origin, target, train, val, test, vectorizer, model, scaler=False):\n",
    "\n",
    "    tokens_str = [' '.join(tokens) for tokens in train[origin]]\n",
    "    vectorizer.fit(tokens_str)\n",
    "\n",
    "    tokens_train = vectorizer.transform(tokens_str)\n",
    "    tokens_val = vectorizer.transform([' '.join(tokens) for tokens in val[origin]])\n",
    "    tokens_test = vectorizer.transform([' '.join(tokens) for tokens in test[origin]])\n",
    "\n",
    "    if scaler:\n",
    "        tokens_train = scaler.fit_transform(tokens_train)\n",
    "        tokens_val = scaler.transform(tokens_val)\n",
    "        tokens_test = scaler.transform(tokens_test)\n",
    "\n",
    "    model.fit(tokens_train, train[target])\n",
    "\n",
    "    train_preds = model.predict(tokens_train)\n",
    "    val_preds = model.predict(tokens_val)\n",
    "    test_preds = model.predict(tokens_test)\n",
    "\n",
    "    train_acc = accuracy_score(train[target], train_preds)\n",
    "    val_acc = accuracy_score(val[target], val_preds)\n",
    "    test_acc = accuracy_score(test[target], test_preds)\n",
    "\n",
    "    result = {\n",
    "        'Origin': origin,\n",
    "        'Target': target,\n",
    "        'Model': model.__class__.__name__,\n",
    "        'Scaler': scaler.__class__.__name__ if scaler else None,\n",
    "        'Vectorizer': vectorizer.__class__.__name__,\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Validation Accuracy': val_acc,\n",
    "        'Test Accuracy': test_acc\n",
    "    }\n",
    "\n",
    "    wasabi.msg.info(f\"Done training {model.__class__.__name__} model with {vectorizer.__class__.__name__} vectorizer and {scaler.__class__.__name__ if scaler else 'no'} scaler.\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "grid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training MultinomialNB model with CountVectorizer vectorizer and\n",
      "no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training MultinomialNB model with CountVectorizer vectorizer and\n",
      "no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training MultinomialNB model with CountVectorizer vectorizer and\n",
      "no scaler.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "origin = 'Title_tokens'\n",
    "\n",
    "target = 'Type'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "experiment = baseline(origin, target, train, val, test, vectorizer=CountVectorizer(), model=MultinomialNB())\n",
    "grid.append(experiment)\n",
    "\n",
    "target = 'Town'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "experiment = baseline(origin, target, train, val, test, vectorizer=CountVectorizer(), model=MultinomialNB())\n",
    "grid.append(experiment)\n",
    "\n",
    "target = 'Polarity'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "experiment = baseline(origin, target, train, val, test, vectorizer=CountVectorizer(), model=MultinomialNB())\n",
    "grid.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training MultinomialNB model with CountVectorizer vectorizer and\n",
      "no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training MultinomialNB model with CountVectorizer vectorizer and\n",
      "no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and no scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training MultinomialNB model with CountVectorizer vectorizer and\n",
      "no scaler.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "origin = 'Review_tokens'\n",
    "\n",
    "target = 'Type'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "experiment = baseline(origin, target, train, val, test, vectorizer=CountVectorizer(), model=MultinomialNB())\n",
    "grid.append(experiment)\n",
    "\n",
    "target = 'Town'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "experiment = baseline(origin, target, train, val, test, vectorizer=CountVectorizer(), model=MultinomialNB())\n",
    "grid.append(experiment)\n",
    "\n",
    "target = 'Polarity'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "experiment = baseline(origin, target, train, val, test, vectorizer=CountVectorizer(), model=MultinomialNB())\n",
    "grid.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridf = pd.DataFrame(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model for each target\n",
    "\n",
    "gridf.sort_values('Test Accuracy', ascending=True).groupby('Target').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and MaxAbsScaler scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and MaxAbsScaler scaler.\u001b[0m\n",
      "\u001b[38;5;4mℹ Done training LogisticRegression model with CountVectorizer\n",
      "vectorizer and MaxAbsScaler scaler.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "\n",
    "origin = 'Review_tokens'\n",
    "\n",
    "target = 'Type'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    scaler=MaxAbsScaler(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "\n",
    "target = 'Town'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    scaler=MaxAbsScaler(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)\n",
    "\n",
    "target = 'Polarity'\n",
    "experiment = baseline(\n",
    "    origin, target, train, val, test,\n",
    "    vectorizer=CountVectorizer(),\n",
    "    scaler=MaxAbsScaler(),\n",
    "    model=LogisticRegression(max_iter=1000,  solver='lbfgs')\n",
    ")\n",
    "grid.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridf = pd.DataFrame(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Origin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Scaler",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Vectorizer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Train Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Validation Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Test Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a42ef6aa-2b0b-4fc9-9c7b-9aec39019a09",
       "rows": [
        [
         "0",
         "Title_tokens",
         "Type",
         "LogisticRegression",
         null,
         "CountVectorizer",
         "0.7936976890244684",
         "0.7589963790175281",
         "0.7589156973949822"
        ],
        [
         "1",
         "Title_tokens",
         "Type",
         "MultinomialNB",
         null,
         "CountVectorizer",
         "0.7795857419346569",
         "0.7565289838818214",
         "0.7543977698740748"
        ],
        [
         "2",
         "Title_tokens",
         "Town",
         "LogisticRegression",
         null,
         "CountVectorizer",
         "0.4184685781668568",
         "0.3591181465696799",
         "0.3580217245025473"
        ],
        [
         "3",
         "Title_tokens",
         "Town",
         "MultinomialNB",
         null,
         "CountVectorizer",
         "0.38816826670426435",
         "0.3451148780722274",
         "0.3442756897048928"
        ],
        [
         "4",
         "Title_tokens",
         "Polarity",
         "LogisticRegression",
         null,
         "CountVectorizer",
         "0.7252720491162409",
         "0.679751337840869",
         "0.6900893972892435"
        ],
        [
         "5",
         "Title_tokens",
         "Polarity",
         "MultinomialNB",
         null,
         "CountVectorizer",
         "0.7166523539137902",
         "0.6744961066427404",
         "0.6840334518888782"
        ],
        [
         "6",
         "Review_tokens",
         "Type",
         "LogisticRegression",
         null,
         "CountVectorizer",
         "0.9839013573616683",
         "0.9486012753548884",
         "0.9462174372777084"
        ],
        [
         "7",
         "Review_tokens",
         "Type",
         "MultinomialNB",
         null,
         "CountVectorizer",
         "0.9421871595380612",
         "0.9369372256224565",
         "0.9367009516485629"
        ],
        [
         "8",
         "Review_tokens",
         "Town",
         "LogisticRegression",
         null,
         "CountVectorizer",
         "0.9048244658352452",
         "0.6699138013907137",
         "0.667211381332308"
        ],
        [
         "9",
         "Review_tokens",
         "Town",
         "MultinomialNB",
         null,
         "CountVectorizer",
         "0.6013727425370743",
         "0.5348479507802737",
         "0.535758915697395"
        ],
        [
         "10",
         "Review_tokens",
         "Polarity",
         "LogisticRegression",
         null,
         "CountVectorizer",
         "0.8623476332688191",
         "0.6818021597718461",
         "0.6846102085936749"
        ],
        [
         "11",
         "Review_tokens",
         "Polarity",
         "MultinomialNB",
         null,
         "CountVectorizer",
         "0.7382496571348005",
         "0.6722530201557343",
         "0.6778333173123138"
        ],
        [
         "12",
         "Review_tokens",
         "Type",
         "LogisticRegression",
         "MaxAbsScaler",
         "CountVectorizer",
         "0.9775503403017214",
         "0.9483128785208447",
         "0.946698067865039"
        ],
        [
         "13",
         "Review_tokens",
         "Town",
         "LogisticRegression",
         "MaxAbsScaler",
         "CountVectorizer",
         "0.848190825311783",
         "0.6432531162880123",
         "0.6401038162068634"
        ],
        [
         "14",
         "Review_tokens",
         "Polarity",
         "LogisticRegression",
         "MaxAbsScaler",
         "CountVectorizer",
         "0.8525166946513029",
         "0.6852949658730413",
         "0.6902335864654426"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Target</th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title_tokens</td>\n",
       "      <td>Type</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.793698</td>\n",
       "      <td>0.758996</td>\n",
       "      <td>0.758916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title_tokens</td>\n",
       "      <td>Type</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.779586</td>\n",
       "      <td>0.756529</td>\n",
       "      <td>0.754398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title_tokens</td>\n",
       "      <td>Town</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.418469</td>\n",
       "      <td>0.359118</td>\n",
       "      <td>0.358022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title_tokens</td>\n",
       "      <td>Town</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.388168</td>\n",
       "      <td>0.345115</td>\n",
       "      <td>0.344276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title_tokens</td>\n",
       "      <td>Polarity</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.725272</td>\n",
       "      <td>0.679751</td>\n",
       "      <td>0.690089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title_tokens</td>\n",
       "      <td>Polarity</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.716652</td>\n",
       "      <td>0.674496</td>\n",
       "      <td>0.684033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Type</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.983901</td>\n",
       "      <td>0.948601</td>\n",
       "      <td>0.946217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Type</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.942187</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.936701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Town</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.904824</td>\n",
       "      <td>0.669914</td>\n",
       "      <td>0.667211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Town</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.601373</td>\n",
       "      <td>0.534848</td>\n",
       "      <td>0.535759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Polarity</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.862348</td>\n",
       "      <td>0.681802</td>\n",
       "      <td>0.684610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Polarity</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.738250</td>\n",
       "      <td>0.672253</td>\n",
       "      <td>0.677833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Type</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.977550</td>\n",
       "      <td>0.948313</td>\n",
       "      <td>0.946698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Town</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.848191</td>\n",
       "      <td>0.643253</td>\n",
       "      <td>0.640104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>Polarity</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.852517</td>\n",
       "      <td>0.685295</td>\n",
       "      <td>0.690234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Origin    Target               Model        Scaler  \\\n",
       "0    Title_tokens      Type  LogisticRegression          None   \n",
       "1    Title_tokens      Type       MultinomialNB          None   \n",
       "2    Title_tokens      Town  LogisticRegression          None   \n",
       "3    Title_tokens      Town       MultinomialNB          None   \n",
       "4    Title_tokens  Polarity  LogisticRegression          None   \n",
       "5    Title_tokens  Polarity       MultinomialNB          None   \n",
       "6   Review_tokens      Type  LogisticRegression          None   \n",
       "7   Review_tokens      Type       MultinomialNB          None   \n",
       "8   Review_tokens      Town  LogisticRegression          None   \n",
       "9   Review_tokens      Town       MultinomialNB          None   \n",
       "10  Review_tokens  Polarity  LogisticRegression          None   \n",
       "11  Review_tokens  Polarity       MultinomialNB          None   \n",
       "12  Review_tokens      Type  LogisticRegression  MaxAbsScaler   \n",
       "13  Review_tokens      Town  LogisticRegression  MaxAbsScaler   \n",
       "14  Review_tokens  Polarity  LogisticRegression  MaxAbsScaler   \n",
       "\n",
       "         Vectorizer  Train Accuracy  Validation Accuracy  Test Accuracy  \n",
       "0   CountVectorizer        0.793698             0.758996       0.758916  \n",
       "1   CountVectorizer        0.779586             0.756529       0.754398  \n",
       "2   CountVectorizer        0.418469             0.359118       0.358022  \n",
       "3   CountVectorizer        0.388168             0.345115       0.344276  \n",
       "4   CountVectorizer        0.725272             0.679751       0.690089  \n",
       "5   CountVectorizer        0.716652             0.674496       0.684033  \n",
       "6   CountVectorizer        0.983901             0.948601       0.946217  \n",
       "7   CountVectorizer        0.942187             0.936937       0.936701  \n",
       "8   CountVectorizer        0.904824             0.669914       0.667211  \n",
       "9   CountVectorizer        0.601373             0.534848       0.535759  \n",
       "10  CountVectorizer        0.862348             0.681802       0.684610  \n",
       "11  CountVectorizer        0.738250             0.672253       0.677833  \n",
       "12  CountVectorizer        0.977550             0.948313       0.946698  \n",
       "13  CountVectorizer        0.848191             0.643253       0.640104  \n",
       "14  CountVectorizer        0.852517             0.685295       0.690234  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Origin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Scaler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Vectorizer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Train Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Validation Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Test Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "590b31cd-80c7-468d-9477-2f1d1833dcdc",
       "rows": [
        [
         "Polarity",
         "Review_tokens",
         "LogisticRegression",
         "MaxAbsScaler",
         "CountVectorizer",
         "0.8525166946513029",
         "0.6852949658730413",
         "0.6902335864654426"
        ],
        [
         "Town",
         "Review_tokens",
         "LogisticRegression",
         "MaxAbsScaler",
         "CountVectorizer",
         "0.9048244658352452",
         "0.6699138013907137",
         "0.667211381332308"
        ],
        [
         "Type",
         "Review_tokens",
         "LogisticRegression",
         "MaxAbsScaler",
         "CountVectorizer",
         "0.9775503403017214",
         "0.9483128785208447",
         "0.946698067865039"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Polarity</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.852517</td>\n",
       "      <td>0.685295</td>\n",
       "      <td>0.690234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Town</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.904824</td>\n",
       "      <td>0.669914</td>\n",
       "      <td>0.667211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>Review_tokens</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.977550</td>\n",
       "      <td>0.948313</td>\n",
       "      <td>0.946698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Origin               Model        Scaler       Vectorizer  \\\n",
       "Target                                                                       \n",
       "Polarity  Review_tokens  LogisticRegression  MaxAbsScaler  CountVectorizer   \n",
       "Town      Review_tokens  LogisticRegression  MaxAbsScaler  CountVectorizer   \n",
       "Type      Review_tokens  LogisticRegression  MaxAbsScaler  CountVectorizer   \n",
       "\n",
       "          Train Accuracy  Validation Accuracy  Test Accuracy  \n",
       "Target                                                        \n",
       "Polarity        0.852517             0.685295       0.690234  \n",
       "Town            0.904824             0.669914       0.667211  \n",
       "Type            0.977550             0.948313       0.946698  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridf.sort_values('Test Accuracy', ascending=False).groupby('Target').first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
